{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6beb5c",
   "metadata": {},
   "source": [
    "We will be working on the built in MNIST Tensorflow dataset, this dataset contains 70000 images of handwritten from 0 to 9, each image is in 28x28 dimension in grayscale only.It has been split into 60000 train set and 10000 test set, for that we will need to create a validation dataset to set early stopping mechanism and pervent overfitting.\n",
    "\n",
    "#### The plan \n",
    "- first we will be using a convolutional layer with kernel size 5x5 and 50 kernels(we won't use a dense layer as that would unpack the 2D image to 1D vector which is far from our desired result) with the ReLu as activation function as it behaves well in most situations.\n",
    "- Our second layer would be a maxpool layer and have a 2x2 kernels with stride 2\n",
    "then we will redo the two layers with a kernel of 3x3 for the convolution and a 50 kernels.\n",
    "then we will flatten the vector (5x5x50) into a 1250 vector and put it into a dense layer that corresponds to 10 digits we want to classify with softmax activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b9d9d2",
   "metadata": {},
   "source": [
    "### Importing relevant libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "842333de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zinel\\anaconda3\\envs\\py3-TF2.0\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b34449",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size=70_000#the maximum batch for shuffling the dataset\n",
    "batch_size=128\n",
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cba5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data,info=tfds.load(name='mnist',with_info=True,as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8355ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=data['train'],data['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb869c",
   "metadata": {},
   "source": [
    "### Scaling the data [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b47217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image,label):\n",
    "    image=tf.cast(image,tf.float32)\n",
    "    image/=255.\n",
    "    return image,label\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e15ad1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_data=train.map(scale)\n",
    "test_data=test.map(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c1e03",
   "metadata": {},
   "source": [
    "### Creating validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da7e8b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = 0.1*info.splits['train'].num_examples\n",
    "num_validation_samples=tf.cast(num_validation_samples,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48bf60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples=info.splits['test'].num_examples\n",
    "num_test_samples=tf.cast(num_test_samples,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c514090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick shuffle before split\n",
    "train_and_validation_data=train_and_validation_data.shuffle(buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d2cd79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_and_validation_data.skip(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "772ae4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data=train_and_validation_data.take(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1e4843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batching the data, preferable a power of 2\n",
    "train_data=train_data.batch(batch_size)\n",
    "# the validation and test sets don't need to be batched as we don't backpropagate on them\n",
    "#but the model expects them to be batched as well to get the proper dimension with their number of samples\n",
    "validation_data=validation_data.batch(num_validation_samples)\n",
    "test_data=test_data.batch(num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380674e6",
   "metadata": {},
   "source": [
    "### Outlining the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11220885",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50,5,activation='relu',input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Conv2D(50,3,activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96934707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      " Layer (type)                    Output Shape                  Param #     \n",
      "===========================================================================\n",
      " conv2d (Conv2D)                 (None, 24, 24, 50)            1300        \n",
      "                                                                           \n",
      " max_pooling2d (MaxPooling2D)    (None, 12, 12, 50)            0           \n",
      "                                                                           \n",
      " conv2d_1 (Conv2D)               (None, 10, 10, 50)            22550       \n",
      "                                                                           \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 50)              0           \n",
      "                                                                           \n",
      " flatten (Flatten)               (None, 1250)                  0           \n",
      "                                                                           \n",
      " dense (Dense)                   (None, 10)                    12510       \n",
      "                                                                           \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length=75) #to check if the model works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51568b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for classification problems we need the sparseCategoricalCrossEntropy loss function\n",
    "loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# this would be the loss function if we had a softmax activation\n",
    "# we avoid inserting the softmax in the model for numerical stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f8efba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2816\\2881040454.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss=loss_fn,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e799e97",
   "metadata": {},
   "source": [
    "Now we should setup an early stopping mechanism to avoid overfitting, in tensorflow this is done using callbacks, callbacks are executed at the end of aech epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3778735",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping=tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',#indicates which property to monitor during training\n",
    "    mode='auto',\n",
    "    min_delta=0,\n",
    "    patience=2,\n",
    "    verbose=0,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "663d272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e7ba144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 68s - loss: 0.2653 - accuracy: 0.9258 - val_loss: 0.0897 - val_accuracy: 0.9748 - 68s/epoch - 160ms/step\n",
      "Epoch 2/20\n",
      "422/422 - 55s - loss: 0.0739 - accuracy: 0.9777 - val_loss: 0.0505 - val_accuracy: 0.9835 - 55s/epoch - 130ms/step\n",
      "Epoch 3/20\n",
      "422/422 - 68s - loss: 0.0534 - accuracy: 0.9842 - val_loss: 0.0463 - val_accuracy: 0.9853 - 68s/epoch - 162ms/step\n",
      "Epoch 4/20\n",
      "422/422 - 63s - loss: 0.0448 - accuracy: 0.9866 - val_loss: 0.0351 - val_accuracy: 0.9895 - 63s/epoch - 150ms/step\n",
      "Epoch 5/20\n",
      "422/422 - 50s - loss: 0.0383 - accuracy: 0.9883 - val_loss: 0.0331 - val_accuracy: 0.9892 - 50s/epoch - 119ms/step\n",
      "Epoch 6/20\n",
      "422/422 - 48s - loss: 0.0322 - accuracy: 0.9900 - val_loss: 0.0256 - val_accuracy: 0.9918 - 48s/epoch - 113ms/step\n",
      "Epoch 7/20\n",
      "422/422 - 48s - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.0218 - val_accuracy: 0.9927 - 48s/epoch - 113ms/step\n",
      "Epoch 8/20\n",
      "422/422 - 47s - loss: 0.0254 - accuracy: 0.9920 - val_loss: 0.0188 - val_accuracy: 0.9935 - 47s/epoch - 112ms/step\n",
      "Epoch 9/20\n",
      "422/422 - 47s - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.0135 - val_accuracy: 0.9963 - 47s/epoch - 112ms/step\n",
      "Epoch 10/20\n",
      "422/422 - 48s - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.0173 - val_accuracy: 0.9935 - 48s/epoch - 115ms/step\n",
      "Epoch 11/20\n",
      "422/422 - 51s - loss: 0.0166 - accuracy: 0.9947 - val_loss: 0.0134 - val_accuracy: 0.9960 - 51s/epoch - 121ms/step\n",
      "Epoch 12/20\n",
      "422/422 - 48s - loss: 0.0156 - accuracy: 0.9952 - val_loss: 0.0126 - val_accuracy: 0.9962 - 48s/epoch - 114ms/step\n",
      "Epoch 13/20\n",
      "422/422 - 44s - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0140 - val_accuracy: 0.9952 - 44s/epoch - 103ms/step\n",
      "Epoch 14/20\n",
      "422/422 - 43s - loss: 0.0121 - accuracy: 0.9962 - val_loss: 0.0072 - val_accuracy: 0.9977 - 43s/epoch - 102ms/step\n",
      "Epoch 15/20\n",
      "422/422 - 43s - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0075 - val_accuracy: 0.9973 - 43s/epoch - 102ms/step\n",
      "Epoch 16/20\n",
      "422/422 - 44s - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.0113 - val_accuracy: 0.9962 - 44s/epoch - 105ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19742714f48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback,early_stopping],#always keep the early stopping the last element of the list, otherwise it bugs out\n",
    "    validation_data=validation_data,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef49715",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26bb4145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step - loss: 0.0281 - accuracy: 0.9914\n"
     ]
    }
   ],
   "source": [
    "test_loss,test_accuracy=model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8679399",
   "metadata": {},
   "source": [
    "Pretty good accuracy, good job soldier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6545bb19",
   "metadata": {},
   "source": [
    "### Plotting images and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b47e2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64cba473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split yhe test_data into 2 arrays, containing the images and the corresponding labels\n",
    "for images,labels in test_data.take(1):\n",
    "    images_test=images.numpy()\n",
    "    labels_test=labels.numpy()\n",
    "    \n",
    "#rehape the images into 28x28\n",
    "images_plot=np.reshape(images_test,(10000,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "572699bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK8AAACuCAYAAABAzl3QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEjUlEQVR4nO3dvy8saxyA8XFzE7F2E3oOBQ06BYnIFipRCy1/gEoUGokf0VEIBaU/QEIlERWiodPoyCYKURGtW9zkNu/XZp1d9+wznk/5zXuOyebJJDPvzG7Lx8fHRyYB/fWnD0D6XcYrLOMVlvEKy3iFZbzCMl5hGa+wjFdYf9e6sKWl5TuPQ/pPrZu+nnmFZbzCMl5hGa+wjFdYxiss4xWW8QrLeIVlvMIyXmEZr7CMV1jGKyzjFVbNz/OqcQqFQjhfWlpKZisrK+Hazc3NZLa8vFzfgcF45hWW8QrLeIVlvMIyXmG11Pr9vL493DgLCwvhfGtrK5nd3d2Fa6emppJZpVKp78CahG8PK/eMV1jGKyzjFZYXbN9oaGgonF9cXITzk5OTZBZtGWdZlj09Pf3+gTU5L9iUe8YrLOMVlvEKy3iF5cPo36hYLH5pvrGxkczyfFehXp55hWW8wjJeYRmvsNwebpCOjo5kdn19Ha59f38P5+VyOZm9vr7WdVxEbg8r94xXWMYrLOMVlvEKy+3hBpmdnU1mfX194dq5ublw/hPvLNTDM6+wjFdYxiss4xWW28MNcnx8nMx+/foVrh0fHw/nXrD9y+1h5Z7xCst4hWW8wjJeYbk9/EXDw8PhPPqy56urq3CtdxUawzOvsIxXWMYrLOMVltvDX/T4+BjOS6VSMhsZGQnX3t/fN/SY8sbtYeWe8QrLeIVlvMIyXmG5PVzF6OhoMuvs7AzXHh4eJjPvKnwvz7zCMl5hGa+wjFdYXrBV0d3dncza2trCtYVCIZlNT0+Ha8/Pz8P5y8vLF45OnnmFZbzCMl5hGa+wjFdYPoxexenpaTKbmJgI10afz2cf7fPzczjf29tLZmtra9UOMZd8GF25Z7zCMl5hGa+wvGDL4ud2syzLLi8vk9nb21u4Nvp82tvb6zuwLMsWFxfD+fb2dt3/d7Pygk25Z7zCMl5hGa+wjFdYPoxeRXTVu7q6Gq49OztLZv39/eHamZmZcB59QXU0y7J8322olWdeYRmvsIxXWMYrLLeHs8+3hy8uLpJZb29vuLZSqdR9HA8PDzWv7enpqfvvNSu3h5V7xiss4xWW8QrLeIXl9nCTu729/dOH0LQ88wrLeIVlvMIyXmF5wVZFtCVeLBZr/vetra3hfGdnJ5x3dXUls/X19Zr/3k/jmVdYxiss4xWW8QrLeIXl3YYqooeij46OwrW7u7vJbGBgIFw7Pz8fzvf395PZwcFBtUP80TzzCst4hWW8wjJeYfn2cJZlpVIpnEdvDw8ODoZrv/JrQJ+9aTw8PJzMfuLvEfv2sHLPeIVlvMIyXmEZr7C821DF2NhYMvvst4DL5XIyu7m5CddOTk6G8594ZyHi3QblnvEKy3iFZbzC8oJNTccLNuWe8QrLeIVlvMIyXmEZr7CMV1jGKyzjFZbxCst4hWW8wjJeYRmvsIxXWMYrLOMVlvEKy3iFZbzCMl5hGa+wjFdYxiss4xWW8QrLeIVV828P1/r9UdL/xTOvsIxXWMYrLOMVlvEKy3iFZbzCMl5hGa+w/gGVp/KegbOUOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The image to be displayed and tested \n",
    "i=27\n",
    "\n",
    "#plot the image\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1],cmap=\"gray\",aspect='auto')\n",
    "\n",
    "#print the correct label for the image\n",
    "print(\"Label: {}\".format(labels_test[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1f5c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 526ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#obtain the model's predictions(logits)\n",
    "predictions=model.predict(images_test[i-1:i])\n",
    "\n",
    "#convert those predictions into probabilities(recall that we incorporated the softmax activation)\n",
    "probabilities=tf.nn.softmax(predictions).numpy()\n",
    "\n",
    "#convert the probabilities into percentages\n",
    "probabilities=probabilities*100\n",
    "\n",
    "#create a bar chart to plot the probabilities for each class\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0],tick_label=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc1195",
   "metadata": {},
   "source": [
    "### Vusualising in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80763c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c212c4",
   "metadata": {},
   "source": [
    "### Computing the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "798425e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce6a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "    class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a110b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
